the project proposes a distributed key-value store implementation that is scalable and fault-tolerant. a front-end node, a data node, a consensus layer, and metadata management are also included in the architecture. II. front-end nodes receive requests from clients and handle routing and read/write operations according to the location of the data. the DHT reduces request handling latency and guarantees balanced load distribution. front-end node caching improves speed by buffering frequently accessed data locally. dynamic changes for data location and shard mappings enables data rebalancing while also altering shard locations for maximum performance and load balancing. the adaptive quorum approach was made extremely successful in meeting high-performance needs by adjusting the sizes of read/write quorums while maintaining full scalability without sacrificing data consistency. Consistent CRDTs eventually provided low latency response for noncritical data that can tolerate some inconsistency. 